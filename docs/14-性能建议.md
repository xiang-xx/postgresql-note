# 14-性能建议


## 使用 EXPLAIN

example
```sql
EXPLAIN SELECT * FROM tenk1;
                         QUERY PLAN
-------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..458.00 rows=10000 width=244
```
explain 预估的数字内容
- 预估启动消耗
- 预估总消耗，消耗是根据 disk_page_red * seq_page_cost + row_scanned * cpu_tuple_cost 算出来的
- 预估 plan node 输出的 rows，并不代表扫描或处理的行
- 预估每行的 width -- bytes

```sql
EXPLAIN SELECT * FROM tenk1 WHERE unique1 < 7000;
                         QUERY PLAN
------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..483.00 rows=7001 width=244)
   Filter: (unique1 < 7000)
```
Filter 代表每一行都会经过 Filter 条件的检查。

```sql
EXPLAIN SELECT * FROM tenk1 WHERE unique1 < 100;
                                  QUERY PLAN
-------------------------------------------------------------------
-----------
 Bitmap Heap Scan on tenk1  (cost=5.07..229.20 rows=101 width=244)
   Recheck Cond: (unique1 < 100)
   ->  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.04
 rows=101 width=0)
         Index Cond: (unique1 < 10
```
两步 scan：子 scan 通过索引，查询的行数比较少，父 scan 回表获取数据，数据顺序是表顺序，不是索引顺序。

```sql
EXPLAIN SELECT * FROM tenk1 WHERE unique1 = 42;
                                 QUERY PLAN
-------------------------------------------------------------------
----------
 Index Scan using tenk1_unique1 on tenk1  (cost=0.29..8.30 rows=1
 width=244)
   Index Cond: (unique1 = 42)
```
上面这个例子中，行的获取是通过 index 顺序，再回表查询。因为行数少，所以才使用这种方式。

Incremental Sort: 使用索引排序，并 limit 返回数量，只需要访问部分数据即可。

BitMapAnd: 一般下面会有若干 BitMap Index Scan 子节点。比如使用两个索引条件再进行交集处理。
```sql
EXPLAIN SELECT * FROM tenk1 WHERE unique1 < 100 AND unique2 > 9000;

Bitmap Heap Scan on tenk1  (cost=25.08..60.21 rows=10 width=244)
   Recheck Cond: ((unique1 < 100) AND (unique2 > 9000))
   ->  BitmapAnd  (cost=25.08..25.08 rows=10 width=0)
         ->  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.04
 rows=101 width=0)
               Index Cond: (unique1 < 100)
         ->  Bitmap Index Scan on tenk1_unique2  (cost=0.00..19.78
 rows=999 width=0)
               Index Cond: (unique2 > 9000)
```

```sql
EXPLAIN SELECT * FROM tenk1 WHERE unique1 < 100 AND unique2 > 9000
 LIMIT 2;

-- 因为使用了 Limit，则不再使用 BitmapAnd，另一个索引使用 filter
Limit  (cost=0.29..14.48 rows=2 width=244)
   ->  Index Scan using tenk1_unique2 on tenk1  (cost=0.29..71.27
 rows=10 width=244)
         Index Cond: (unique2 > 9000)
         Filter: (unique1 < 100)
```

嵌套循环
```sql
EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 < 10 AND t1.unique2 = t2.unique2;
                                      QUERY PLAN
-------------------------------------------------------------------
-------------------
 Nested Loop  (cost=4.65..118.62 rows=10 width=488)
   ->  Bitmap Heap Scan on tenk1 t1  (cost=4.36..39.47 rows=10
 width=244)
         Recheck Cond: (unique1 < 10)
         ->  Bitmap Index Scan on tenk1_unique1  (cost=0.00..4.36
 rows=10 width=0)
               Index Cond: (unique1 < 10)
   ->  Index Scan using tenk2_unique2 on tenk2 t2  (cost=0.29..7.91
 rows=1 width=244)
         Index Cond: (unique2 = t1.unique2
```

HashJoin：第一张表的数据根据 join 的键放入 hash 表...
MergeJoin：jion 的键都必须是有序的

**EXPLAIN ANALYZE** 会实际执行查询，并返回实际运行的情况 -- 扫描行数，花费，执行计划等。

对于更新插入删除的性能检测，可以先开启事务，再使用 EXPLAIN ANALYZE，最后 rollback 事务。


## Planner 使用的静态统计

表和索引的静态统计信息存储在 pg_class 表中。此表的数据并非实时更新，而是在 VACUUM, ANALYZE 和一些 DDL 语句比如 CREATE INDEX 执行时才会更新。

WHERE 语预估过滤的行数，信息存储在 pg_statistic 表，数据只会在执行 ANALYZE 和 VACUUM ANALYZE 才会更新。

只能 superuser 才能读取 pg_statistic；所有用户都可以读取 pg_stats，pg_stats 使用视图维护了每个用户可以看到的数据。

此外，可以自定义 Statistics，使生成更好的查询计划。


## 使用 JOIN 子语句控制 Planner

example
```sql
SELECT * FROM a, b, c WHERE a.id = b.id AND b.ref = c.id;  -- 无法确定生成的执行计划里 谁 join 谁
SELECT * FROM a LEFT JOIN (b JOIN c ON (b.ref = c.id)) ON (a.id = b.id);  -- 确定 join 顺序，planner 也省去了估算 join 顺序的时间
```

## 填充数据库

当使用大量 INSERT 时，最好在一个事务里提交所有 INSERT。

使用 COPY 命令，比 INSERT 快。

使用 PREPARE 准备一个 INSERT 语句，使用 EXECUTE 填充数据。

如果向新表中添加大量数据，可以先加数据，后创建索引。如果向已存在的表中添加大量数据，可以先删除索引，后添加数据，再创建索引。如果存在外键，也是同样的道理。

暂时性增加 maintenance_work_mem 的配置，对于 CREATE INDEX, 以及 ADD FOREIGN KEY 命令有帮助。

大量载入数据时，暂时性增加 max_wal_size 可以使 checkpoint 数量减少，减少脏页 flush 的频率，再快数据载入速度。

禁用 WAL Archival 和 Streaming Replication。

数据载入后，运行 ANALYZE。

pg_dump 导入导出数据。


## 非持久化设置

刚好与持久化配置反着来。没有持久化，速度更快。一般来说还是不要用。

非持久化配置：
- 存储数据配置在内存文件系统
- 关闭 fsync，不要把数据 flush 到 disk 上
- 关闭 synchronous_commit，没必要在事务提交时把 WAL 写入磁盘
- 关闭 full_page_write，不用管部分 page 写入。
- 增加 max_wal_size，以减少 checkpoint
- 创建 unlogged tables 避免 WAL
- ...
